# TM-New-Word

Topic Model with an Infinite Vocabulary

Purpose: Due to the continuous growth of the internet, increase in quantity of news, email messages, posts in blogs, the demand for Natural Language Processing systems is growing. One of the popular and promising areas of machine learning and natural language processing is algorithms of topic model. The most ways of topic models deal with static information with a final vocabulary, and in practice, we need tools to work with a refillable vocabulary. Every year new words appear, some words become obsolete, so the refillable vocabulary is especially important for Online Topic Model. The goal: Developing approach, determining the vector of a topic new word using the Hadamard product of vectors thematic documents, where the word is encountered, which will be an alternative approach using a Dirichlet distribution or Dirichlet process. Results: the study shows that the amount of topic vectors in the documents with a new word gives the wrong idea about the topic of a new word. At the same time, it is better to use the Hadamard product to situate the topic of a new word in the documents topics. Multiplying entrywise topic vectors of the document with a new word cancels non-overlapping thematic subjects’ vectors documents, the documents in which the values of probability topics are similar in meaning and significance, giving the greatest contribution to the topic vector of a new word. As a result of the multiplication of vectors, the topic vector of a document gets new words with the highest probability values in several of the most important topics, values weakly expressed topics, or approaches zero, or cancels. Practical importance: the use of the proposed algorithm can increase infinitely online dictionary of topic model, and consequently consider both new and old words. 

Keywords – topic model, natural language processing, machine learning.
