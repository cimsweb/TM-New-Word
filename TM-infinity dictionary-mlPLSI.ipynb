{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Обучаем модель для классификации</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from lxml import objectify\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime, date, time\n",
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import time\n",
    "import sys\n",
    "from sklearn import metrics\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Источник данных</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#В папке TMdata лежит наш XML файл который будем читать. В итоге в Root будут распарсенные XML элементы\n",
    "path = 'TMdata/xmlWikiOrderByDate.xml'\n",
    "parsed = objectify.parse(open(path))\n",
    "root = parsed.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = ['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', \\\n",
    "             'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', \\\n",
    "             'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', \\\n",
    "             'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', \\\n",
    "             'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', \\\n",
    "             'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', \\\n",
    "             'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', \\\n",
    "             'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', \\\n",
    "             'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', \\\n",
    "             'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', \\\n",
    "             'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>DataFrame</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Последняя рабочая долгая версия \n",
    "dftime = pd.DataFrame (columns=('id', 'data', 'category', 'title', 'content'))\n",
    "skip_fieldst2 = ['text', 'userid', 'title', 'data', 'autor', 'id', 'content']\n",
    "for eltime in root.page:\n",
    "    for childt in eltime.getchildren():\n",
    "        if childt.tag in skip_fieldst2:\n",
    "            continue\n",
    "        dout=re.sub(r'(\\d+)-(\\d+)-(\\d+)', r'01-\\2-\\3', eltime.data.pyval)\n",
    "        dd=datetime.strptime(dout, '%d-%m-%Y')\n",
    "        #dd=dd.resample(\"Y\")\n",
    "        rowt = dict(zip(['id', 'data', 'category', 'title', 'content'], \n",
    "                        [eltime.id.pyval, dd, childt.pyval, eltime.title.pyval, eltime.content.pyval]))\n",
    "        row_st = pd.Series(rowt)\n",
    "        row_st.name=eltime.id.pyval\n",
    "        dftime = dftime.append(row_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Сохраняем датафрейм, чтобы постоянно не считать\n",
    "dftime.to_pickle('TMdata/dftime.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Загрузка из датафрейма\n",
    "dftime = pd.read_pickle('TMdata/dftime.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>data</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7376</th>\n",
       "      <td>7376</td>\n",
       "      <td>2005-02-01</td>\n",
       "      <td>Барнаул</td>\n",
       "      <td>Умер Владимир Мефодьевич Башунов</td>\n",
       "      <td>\\n      Сегодня утром из Барнаула пришло печал...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7376</th>\n",
       "      <td>7376</td>\n",
       "      <td>2005-02-01</td>\n",
       "      <td>Алтайский край</td>\n",
       "      <td>Умер Владимир Мефодьевич Башунов</td>\n",
       "      <td>\\n      Сегодня утром из Барнаула пришло печал...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7376</th>\n",
       "      <td>7376</td>\n",
       "      <td>2005-02-01</td>\n",
       "      <td>Некрологи</td>\n",
       "      <td>Умер Владимир Мефодьевич Башунов</td>\n",
       "      <td>\\n      Сегодня утром из Барнаула пришло печал...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7376</th>\n",
       "      <td>7376</td>\n",
       "      <td>2005-02-01</td>\n",
       "      <td>Писатели</td>\n",
       "      <td>Умер Владимир Мефодьевич Башунов</td>\n",
       "      <td>\\n      Сегодня утром из Барнаула пришло печал...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7376</th>\n",
       "      <td>7376</td>\n",
       "      <td>2005-02-01</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Умер Владимир Мефодьевич Башунов</td>\n",
       "      <td>\\n      Сегодня утром из Барнаула пришло печал...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       data        category                             title  \\\n",
       "7376  7376 2005-02-01         Барнаул  Умер Владимир Мефодьевич Башунов   \n",
       "7376  7376 2005-02-01  Алтайский край  Умер Владимир Мефодьевич Башунов   \n",
       "7376  7376 2005-02-01       Некрологи  Умер Владимир Мефодьевич Башунов   \n",
       "7376  7376 2005-02-01        Писатели  Умер Владимир Мефодьевич Башунов   \n",
       "7376  7376 2005-02-01          Россия  Умер Владимир Мефодьевич Башунов   \n",
       "\n",
       "                                                content  \n",
       "7376  \\n      Сегодня утром из Барнаула пришло печал...  \n",
       "7376  \\n      Сегодня утром из Барнаула пришло печал...  \n",
       "7376  \\n      Сегодня утром из Барнаула пришло печал...  \n",
       "7376  \\n      Сегодня утром из Барнаула пришло печал...  \n",
       "7376  \\n      Сегодня утром из Барнаула пришло печал...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftime.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Выбираем категории где больше 50 документов</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>data</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7376</th>\n",
       "      <td>7376</td>\n",
       "      <td>2005-02-01</td>\n",
       "      <td>Некрологи</td>\n",
       "      <td>Умер Владимир Мефодьевич Башунов</td>\n",
       "      <td>\\n      Сегодня утром из Барнаула пришло печал...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7376</th>\n",
       "      <td>7376</td>\n",
       "      <td>2005-02-01</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Умер Владимир Мефодьевич Башунов</td>\n",
       "      <td>\\n      Сегодня утром из Барнаула пришло печал...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>1349</td>\n",
       "      <td>2005-11-01</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Россия удивлена заявлениями Премьер-министра У...</td>\n",
       "      <td>\\n      Украина\\n      В Москве обратили внима...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>1349</td>\n",
       "      <td>2005-11-01</td>\n",
       "      <td>Украина</td>\n",
       "      <td>Россия удивлена заявлениями Премьер-министра У...</td>\n",
       "      <td>\\n      Украина\\n      В Москве обратили внима...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>1349</td>\n",
       "      <td>2005-11-01</td>\n",
       "      <td>Политика</td>\n",
       "      <td>Россия удивлена заявлениями Премьер-министра У...</td>\n",
       "      <td>\\n      Украина\\n      В Москве обратили внима...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       data   category  \\\n",
       "7376  7376 2005-02-01  Некрологи   \n",
       "7376  7376 2005-02-01     Россия   \n",
       "1349  1349 2005-11-01     Россия   \n",
       "1349  1349 2005-11-01    Украина   \n",
       "1349  1349 2005-11-01   Политика   \n",
       "\n",
       "                                                  title  \\\n",
       "7376                   Умер Владимир Мефодьевич Башунов   \n",
       "7376                   Умер Владимир Мефодьевич Башунов   \n",
       "1349  Россия удивлена заявлениями Премьер-министра У...   \n",
       "1349  Россия удивлена заявлениями Премьер-министра У...   \n",
       "1349  Россия удивлена заявлениями Премьер-министра У...   \n",
       "\n",
       "                                                content  \n",
       "7376  \\n      Сегодня утром из Барнаула пришло печал...  \n",
       "7376  \\n      Сегодня утром из Барнаула пришло печал...  \n",
       "1349  \\n      Украина\\n      В Москве обратили внима...  \n",
       "1349  \\n      Украина\\n      В Москве обратили внима...  \n",
       "1349  \\n      Украина\\n      В Москве обратили внима...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftimeR=dftime.groupby(['category']).filter(lambda x: x['category'].value_counts() > 50)\n",
    "dftimeR.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "Wall time: 4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfTimeUniqCatR=pd.unique(dftimeR.category.ravel())\n",
    "print len(dfTimeUniqCatR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>DataFrame 2</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df4 = pd.DataFrame(columns=('id','content', 'data', 'category'))\n",
    "#i = 0\n",
    "dfList = dftimeMinusCat['category'].tolist()\n",
    "skip_fields4 = ['category']\n",
    "for el4 in root.page:\n",
    "    el_cat=[]\n",
    "    for child4 in el4.getchildren():\n",
    "        if child4.tag in skip_fields4:\n",
    "            if child4.pyval not in dfList:\n",
    "                el_cat.append(child4.pyval)\n",
    "    if not el_cat:\n",
    "        #print \"List Empty\"\n",
    "        continue\n",
    "    dout=re.sub(r'(\\d+)-(\\d+)-(\\d+)', r'01-\\2-\\3', el4.data.pyval)\n",
    "    dd=datetime.strptime(dout, '%d-%m-%Y')\n",
    "    el_cat_string = \", \".join(el_cat)\n",
    "    content1 = el4.title.pyval + el4.content.pyval\n",
    "    row4 = dict(zip(['id', 'content', 'data', 'category'], [el4.id.pyval, content1, dd, el_cat_string]))\n",
    "    row_s4 = pd.Series(row4)\n",
    "    row_s4.name = el4.id.pyval\n",
    "    df4 = df4.append(row_s4)\n",
    "    #i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Сохраняем датафрейм, чтобы постоянно не считать\n",
    "df4.to_pickle('TMdata/df4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Загрузка из датафрейма\n",
    "df4 = pd.read_pickle('TMdata/df4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>data</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7376</th>\n",
       "      <td>7376</td>\n",
       "      <td>Умер Владимир Мефодьевич Башунов\\n      Сегодн...</td>\n",
       "      <td>2005-02-01</td>\n",
       "      <td>Некрологи, Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>1349</td>\n",
       "      <td>Россия удивлена заявлениями Премьер-министра У...</td>\n",
       "      <td>2005-11-01</td>\n",
       "      <td>Россия, Украина, Политика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>1353</td>\n",
       "      <td>Впервые зарегистрирован свет самых древних зве...</td>\n",
       "      <td>2005-11-01</td>\n",
       "      <td>Астрономия, Опубликовано</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>1359</td>\n",
       "      <td>День народного единства\\n      В России первый...</td>\n",
       "      <td>2005-11-01</td>\n",
       "      <td>Россия, Праздники</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>1361</td>\n",
       "      <td>Беспорядки в Париже\\n      Франция\\n      В Па...</td>\n",
       "      <td>2005-11-01</td>\n",
       "      <td>Франция, Гражданские беспорядки</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                            content       data  \\\n",
       "7376  7376  Умер Владимир Мефодьевич Башунов\\n      Сегодн... 2005-02-01   \n",
       "1349  1349  Россия удивлена заявлениями Премьер-министра У... 2005-11-01   \n",
       "1353  1353  Впервые зарегистрирован свет самых древних зве... 2005-11-01   \n",
       "1359  1359  День народного единства\\n      В России первый... 2005-11-01   \n",
       "1361  1361  Беспорядки в Париже\\n      Франция\\n      В Па... 2005-11-01   \n",
       "\n",
       "                             category  \n",
       "7376                Некрологи, Россия  \n",
       "1349        Россия, Украина, Политика  \n",
       "1353         Астрономия, Опубликовано  \n",
       "1359                Россия, Праздники  \n",
       "1361  Франция, Гражданские беспорядки  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Создаем выборку данных для обучения модели и тестовых данных</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          6428\n",
       "content     6428\n",
       "data        6428\n",
       "category    6428\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          2430\n",
      "content     2430\n",
      "data        2430\n",
      "category    2430\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mask = (df4['data'] >= '2005-01-01') & (df4['data'] < '2012-01-01')\n",
    "df4_5500=df4.loc[mask]\n",
    "print (df4_5500.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          1129\n",
      "content     1129\n",
      "data        1129\n",
      "category    1129\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mask = (df4['data'] >= '2012-01-01') & (df4['data'] < '2013-01-01')\n",
    "df4_5500_new=df4.loc[mask]\n",
    "print (df4_5500_new.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Создаем данные для обучения</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category = df4_5500['category'].tolist()\n",
    "content = df4_5500['content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "category2=[]\n",
    "for line in category:\n",
    "    lines = line.strip().split(', ')\n",
    "    lis=\"\"\n",
    "    for li in lines:\n",
    "        cat = \"_\".join(li.split(' '))\n",
    "        lis += cat + \" \"\n",
    "    category2.append(lis)\n",
    "#print (\"\\n\".join(category2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizerContent = CountVectorizer (min_df=1, stop_words=stop_words)\n",
    "vectorizerCategory = CountVectorizer (min_df=1)\n",
    "#vectorizerDate = CountVectorizer (min_df=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#X-pwd\n",
    "pwd = vectorizerContent.fit_transform(content)\n",
    "#Xcat - pdt\n",
    "pdt = vectorizerCategory.fit_transform(category2)\n",
    "#Xdat = vectorizerDate.fit_transform(dataT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#xx-pwdT\n",
    "pwdT = pwd.toarray().transpose()\n",
    "#xxcat-pdtT\n",
    "pdtT = pdt.toarray().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 134 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "selected_feature_names_Cont = np.asarray(vectorizerContent.get_feature_names())\n",
    "selected_feature_names_Cat = np.asarray(vectorizerCategory.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n",
      "83849\n"
     ]
    }
   ],
   "source": [
    "print len(selected_feature_names_Cat)\n",
    "print len(selected_feature_names_Cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Pwt - матрица тема документ\n",
    "# Pwt = SUM(Ptd * Pdw)\n",
    "i = 0\n",
    "Pwt = 0\n",
    "for xC in pdt:\n",
    "    Pwt += np.array(xC.toarray())*np.array(pwd[i].toarray().transpose())\n",
    "    #print (i)\n",
    "    i += 1\n",
    "#print (Pwt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Сохраняем датафрейм, чтобы постоянно не считать\n",
    "#Pwt.to_pickle('TMdata/Pwt.pkl')\n",
    "np.save('TMdata/Pwt1.npy', Pwt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pwt=np.load('TMdata/Pwt1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83849"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Pwt.T[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "i1 = 0\n",
    "Phi = np.arange(Pwt.size, dtype=float).reshape(Pwt.sum(axis=1).size, Pwt[0].size)\n",
    "for el4 in Pwt.sum(axis=1):\n",
    "    i2 = 0\n",
    "    for el1 in Pwt[i1]:\n",
    "        Phi[i1][i2]=float(el1)/Pwt[i1].sum()\n",
    "        i2 += 1\n",
    "    i1 += 1\n",
    "print (Phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Phi_T=Phi.copy()\n",
    "Phi_T=Phi_T.transpose()\n",
    "len(Phi_T[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Cat_Word = pd.DataFrame(columns=('word','probability', 'count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "i3=0\n",
    "#n=100\n",
    "for k in Phi_T[106]:\n",
    "    #print (u\"Слово %s вероятность %f\" % (selected_feature_names_Cont[i3], k))\n",
    "    row5 = dict(zip(['word', 'probability', 'count'], [selected_feature_names_Cont[i3], k, Pwt[i3][146]]))\n",
    "    row_s5 = pd.Series(row5)\n",
    "    row_s5.name = i3\n",
    "    df_Cat_Word = df_Cat_Word.append(row_s5)\n",
    "    i3+=1\n",
    "    if i3%20000==0:\n",
    "        print i3\n",
    "    #if i3>n:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Cat_Word.sort(['probability', 'count'], ascending=[False, False] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#количество документов в коллекции\n",
    "countDoc = len(content)\n",
    "print (countDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"Уникальных слов в обучении = %s\" % len(Pwt.sum(axis=1)))\n",
    "print (\"Количество категорий = %s\" % len(Pwt.sum(axis=0)))\n",
    "print (\"Слов в коллекции = %s\" % Pwt.sum())\n",
    "print (\"Количество документов = %s\" % df4_5500['id'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Мультиклассовая классификация</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Количество категорий которые выводим\n",
    "maxCat = 50\n",
    "#Количество документов из тестовой выборки\n",
    "bb=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "a = iter(list(range(bb)))\n",
    "for i in a:\n",
    "    numDStart=1050+i\n",
    "    numDEnd=1050+i+1\n",
    "    newD = vectorizerContent.transform(df4[numDStart:numDEnd]['category'].tolist()).toarray()\n",
    "    #print (newD)\n",
    "    j=0\n",
    "    newDT=newD.transpose()\n",
    "    predictMatrix = []\n",
    "    for inNew in np.nditer(newD):\n",
    "        if inNew > 0:\n",
    "            #print (inNew)\n",
    "            wordInDoc = float(pwdT[j].sum())\n",
    "            k = 0\n",
    "            for inCat in Pwt[j]:\n",
    "                if inCat > 0:\n",
    "                    wordInCat = float(pdtT[k].sum())\n",
    "                    el_data= {}\n",
    "                    el_data[selected_feature_names_Cat[k]] = Phi[j][k]*(1-wordInCat/countDoc)*(1-wordInDoc/countDoc)*newDT[j]/newD.sum()\n",
    "                    predictMatrix.append(dict(el_data))\n",
    "                k += 1\n",
    "        j += 1\n",
    "    dfM = DataFrame(predictMatrix)\n",
    "    del predictMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "true1=0\n",
    "false1=0\n",
    "sum1=0\n",
    "true2=[]\n",
    "#test_doc_=random.randint(6000, 7000)\n",
    "\n",
    "a = iter(list(range(bb)))\n",
    "for i in a:\n",
    "    numDStart=1050+i\n",
    "    numDEnd=1050+i+1\n",
    "    newD = vectorizerContent.transform(df4[numDStart:numDEnd]['category'].tolist()).toarray()\n",
    "    #print (newD)\n",
    "    j=0\n",
    "    newDT=newD.transpose()\n",
    "    predictMatrix = []\n",
    "    for inNew in np.nditer(newD):\n",
    "        if inNew > 0:\n",
    "            #print (inNew)\n",
    "            wordInDoc = float(pwdT[j].sum())\n",
    "            k = 0\n",
    "            for inCat in Pwt[j]:\n",
    "                if inCat > 0:\n",
    "                    wordInCat = float(pdtT[k].sum())\n",
    "                    el_data= {}\n",
    "                    el_data[selected_feature_names_Cat[k]] = Phi[j][k]*(1-wordInCat/countDoc)*(1-wordInDoc/countDoc)*newDT[j]/newD.sum()\n",
    "                    predictMatrix.append(dict(el_data))\n",
    "                k += 1\n",
    "        j += 1\n",
    "    dfM = DataFrame(predictMatrix)\n",
    "    del predictMatrix\n",
    "    #print (dfM.head())\n",
    "    \n",
    "    list_test_cat = df4[numDStart:numDEnd]['category'].tolist()\n",
    "    category2_test_=[]\n",
    "    for line in list_test_cat:\n",
    "        lines = line.strip().split(', ')\n",
    "        lis=\"\"\n",
    "        for li in lines:\n",
    "            cat = \"_\".join(li.lower().split(' '))\n",
    "            category2_test_.append(cat)\n",
    "    dfSumM=dfM.sum()\n",
    "    \n",
    "    n = 1\n",
    "    m=0\n",
    "    dfSumM.sort_values(ascending=False, kind='quicksort', na_position='last', inplace=True)\n",
    "    for el in dfSumM.T.iteritems():\n",
    "        sum1+=1\n",
    "        if n < maxCat:\n",
    "            if el[0] in category2_test_:\n",
    "                if n==1:\n",
    "                    true1+=1\n",
    "                #print (\"%s) BINGO %s = %f\" % (n, el[0], el[1]))\n",
    "                m += 1\n",
    "            else:\n",
    "                false1+=1\n",
    "            \n",
    "            n += 1\n",
    "    #print (\", \".join(category2_test_))\n",
    "    true2.append(float((m)/len(category2_test_)))\n",
    "    #print (\"%s из %s\" % (m, len(category2_test_)))\n",
    "        \n",
    "print (\"True %s in %s\" % (true1, bb))\n",
    "print (\"True %f in maxCat %s\" % (sum(true2)/float(len(true2)), maxCat))\n",
    "print (\"False %f \" % (float(false1)/sum1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "newWord = vectorizerContent.transform([u\"выборы президента России\"]).toarray()\n",
    "#print (newWord)\n",
    "predictMatrixW = []\n",
    "j=0\n",
    "for inNew in np.nditer(newWord):\n",
    "    if inNew > 0:\n",
    "        wordInDoc = float(pwdT[j].sum())\n",
    "        k = 0\n",
    "        for inCat in Pwt[j]:\n",
    "            if inCat > 0:\n",
    "                wordInCat = float(pdtT[k].sum())\n",
    "                el_data= {}\n",
    "                el_data[selected_feature_names_Cat[k]] = Phi[j][k]*(1-wordInCat/countDoc)*(1-wordInDoc/countDoc)\n",
    "                predictMatrixW.append(dict(el_data))\n",
    "            k +=1\n",
    "    j+=1\n",
    "dfMW = DataFrame(predictMatrixW)\n",
    "\n",
    "#print (dfM.sum())\n",
    "dfSumMW=dfMW.sum()\n",
    "i =0\n",
    "dfSumMW.sort_values(ascending=False, kind='quicksort', na_position='last', inplace=True)\n",
    "for el in dfSumMW.T.iteritems():\n",
    "    print (\"%s) %s = %f\" % (i, el[0], el[1]))\n",
    "    #if i < 21:\n",
    "    #    print (\"%s) %s = %f\" % (i, el[0], el[1]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Сохраняем датафрейм, чтобы постоянно не считать\n",
    "dfSumMW.to_pickle('TMdata/dfSumMW.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Загрузка из датафрейма\n",
    "dfSumMW = pd.read_pickle('TMdata/dfSumMW.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfV=pd.DataFrame(dfSumMW, columns=['Probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfV2=dfV[0:10]\n",
    "rcParams['font.family'] = 'verdana'\n",
    "rcParams['legend.fontsize'] = 24\n",
    "#xlabel(u\"Категории\")\n",
    "dfV2.plot.bar(figsize=(20, 10), alpha=0.5, color='000', label=u'Кат', fontsize='24');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfV.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Регуляризация</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "i1 = 0\n",
    "Phi1 = np.arange(Pwt1.size, dtype=float).reshape(Pwt1.sum(axis=1).size, Pwt1[0].size)\n",
    "for el4 in Pwt1.sum(axis=1):\n",
    "    i2 = 0\n",
    "    for el1 in Pwt1[i1]:\n",
    "        Phi1[i1][i2]=float(el1)/Pwt1[i1].sum()\n",
    "        i2 += 1\n",
    "    i1 += 1\n",
    "print (Phi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "true1=0\n",
    "false1=0\n",
    "sum1=0\n",
    "true2=[]\n",
    "#test_doc_=random.randint(6000, 7000)\n",
    "\n",
    "a = iter(list(range(bb)))\n",
    "for i in a:\n",
    "    numDStart=5750+i\n",
    "    numDEnd=5750+i+1\n",
    "    newD = vectorizerContent.transform(df4[numDStart:numDEnd]['category'].tolist()).toarray()\n",
    "    #print (newD)\n",
    "    j=0\n",
    "    newDT=newD.transpose()\n",
    "    predictMatrix = []\n",
    "    for inNew in np.nditer(newD):\n",
    "        if inNew > 0:\n",
    "            #print (inNew)\n",
    "            wordInDoc = float(pwdT[j].sum())\n",
    "            k = 0\n",
    "            for inCat in Pwt[j]:\n",
    "                if inCat > 0:\n",
    "                    wordInCat = float(pdtT[k].sum())\n",
    "                    el_data= {}\n",
    "                    el_data[selected_feature_names_Cat[k]] = Phi1[j][k]*(1-wordInCat/countDoc)*(1-wordInDoc/countDoc)*newDT[j]/newD.sum()\n",
    "                    predictMatrix.append(dict(el_data))\n",
    "                k += 1\n",
    "        j += 1\n",
    "    dfM = DataFrame(predictMatrix)\n",
    "    del predictMatrix\n",
    "    #print (dfM.head())\n",
    "    \n",
    "    list_test_cat = df4[numDStart:numDEnd]['category'].tolist()\n",
    "    category2_test_=[]\n",
    "    for line in list_test_cat:\n",
    "        lines = line.strip().split(', ')\n",
    "        lis=\"\"\n",
    "        for li in lines:\n",
    "            cat = \"_\".join(li.lower().split(' '))\n",
    "            category2_test_.append(cat)\n",
    "    dfSumM=dfM.sum()\n",
    "    \n",
    "    n = 1\n",
    "    m=0\n",
    "    dfSumM.sort_values(ascending=False, kind='quicksort', na_position='last', inplace=True)\n",
    "    for el in dfSumM.T.iteritems():\n",
    "        sum1+=1\n",
    "        if n < maxCat:\n",
    "            if el[0] in category2_test_:\n",
    "                if n==1:\n",
    "                    true1+=1\n",
    "                #print (\"%s) BINGO %s = %f\" % (n, el[0], el[1]))\n",
    "                m += 1\n",
    "            else:\n",
    "                false1+=1\n",
    "            \n",
    "            n += 1\n",
    "    #print (\", \".join(category2_test_))\n",
    "    true2.append(float((m)/len(category2_test_)))\n",
    "    #print (\"%s из %s\" % (m, len(category2_test_)))\n",
    "        \n",
    "print (\"True %s in %s\" % (true1, bb))\n",
    "print (\"True %f in maxCat %s\" % (sum(true2)/float(len(true2)), maxCat))\n",
    "print (\"False %f \" % (float(false1)/sum1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "newWord = vectorizerContent.transform([u\"выборы призедента россии\"]).toarray()\n",
    "#print (newWord)\n",
    "newWord?\n",
    "predictMatrixW = []\n",
    "j=0\n",
    "for inNew in np.nditer(newWord):\n",
    "    if inNew > 0:\n",
    "        wordInDoc = float(pwdT[j].sum())\n",
    "        k = 0\n",
    "        for inCat in Pwt[j]:\n",
    "            if inCat > 0:\n",
    "                wordInCat = float(pdtT[k].sum())\n",
    "                el_data= {}\n",
    "                el_data[selected_feature_names_Cat[k]] = Phi[j][k]*(1-wordInCat/countDoc)*(1-wordInDoc/countDoc)\n",
    "                predictMatrixW.append(dict(el_data))\n",
    "            k +=1\n",
    "    j+=1\n",
    "dfMW = DataFrame(predictMatrixW)\n",
    "\n",
    "#print (dfM.sum())\n",
    "dfSumMW=dfMW.sum()\n",
    "i =0\n",
    "dfSumMW.sort_values(ascending=False, kind='quicksort', na_position='last', inplace=True)\n",
    "for el in dfSumMW.T.iteritems():\n",
    "    print (\"%s) %s = %f\" % (i, el[0], el[1]))\n",
    "    #if i < 21:\n",
    "    #    print (\"%s) %s = %f\" % (i, el[0], el[1]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
